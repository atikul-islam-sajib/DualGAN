{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "import joblib\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump(value = None, filename = None):\n",
    "    if (value is not None) and (filename is not None):\n",
    "        joblib.dump(value = value, filename = filename)\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"Please provide the value and filename to dump\".capitalize())\n",
    "    \n",
    "    \n",
    "def load(filename):\n",
    "    if filename is not None:\n",
    "        return joblib.load(filename = filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config():\n",
    "    with open(\"../../config.yml\", \"r\") as file:\n",
    "        config_files = yaml.safe_load(file)\n",
    "        \n",
    "    return config_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader():\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_path = None,\n",
    "        channels = 3,\n",
    "        image_size = 256,\n",
    "        batch_size = 1,\n",
    "        split_size = 0.20,\n",
    "        paired_images = False,\n",
    "        unpaired_images = True\n",
    "        ):\n",
    "        self.image_path = image_path\n",
    "        self.channels = channels\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.split_size = split_size\n",
    "        self.paired_images = paired_images\n",
    "        self.unpaired_images = unpaired_images\n",
    "\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "\n",
    "        self.raw_path = config()[\"path\"][\"raw_path\"]\n",
    "        self.processed_path = config()[\"path\"][\"processed_path\"]\n",
    "\n",
    "    def unzip_folder(self):\n",
    "        with zipfile.ZipFile(self.image_path, \"r\") as file:\n",
    "            if os.path.exists(self.raw_path):\n",
    "                file.extractall(os.path.join(self.raw_path))\n",
    "\n",
    "            else:\n",
    "                raise Exception(\"Cannot unzip the folder for further process\".capitalize())\n",
    "\n",
    "    def transforms(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((self.image_size, self.image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.CenterCrop((self.image_size, self.image_size)),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "    def image_split(self, X, y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=self.split_size, random_state=42\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\": y_train,\n",
    "            \"y_test\": y_test,\n",
    "        }\n",
    "\n",
    "    def feature_extractor(self):\n",
    "        self.directory = os.path.join(self.raw_path, \"images\")\n",
    "        self.categories = [\"X\", \"y\"]\n",
    "\n",
    "        self.paired_check = os.listdir(os.path.join(self.directory, \"y\"))\n",
    "\n",
    "        for category in tqdm(self.categories):   \n",
    "            folder_path = os.path.join(self.directory, category) \n",
    "\n",
    "            for image in os.listdir(folder_path): \n",
    "                if self.paired_images:\n",
    "                    if image in self.paired_check:\n",
    "                        image_path = os.path.join(folder_path, image) \n",
    "                else:\n",
    "                    image_path = os.path.join(folder_path, image)\n",
    "\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                image = self.transforms()(Image.fromarray(image))\n",
    "\n",
    "                self.X.append(image) if category == \"X\" else self.y.append(image)                  \n",
    "\n",
    "        return self.image_split(X = self.X, y = self.y)\n",
    "\n",
    "    def create_dataloader(self):\n",
    "        try:\n",
    "            data = self.feature_extractor()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred while creating the dataloader\".capitalize(), e)\n",
    "\n",
    "        else:\n",
    "            train_dataloader = DataLoader(\n",
    "                dataset=list(zip(data[\"X_train\"], data[\"y_train\"])),\n",
    "                batch_size=self.batch_size,\n",
    "                shuffle=True\n",
    "            )\n",
    "            test_dataloader = DataLoader(\n",
    "                dataset=list(zip(data[\"X_test\"], data[\"y_test\"])),\n",
    "                batch_size=self.batch_size*8,\n",
    "                shuffle=True\n",
    "            )\n",
    "\n",
    "            if os.path.exists(self.processed_path):\n",
    "                dump(\n",
    "                    value=train_dataloader,\n",
    "                    filename=os.path.join(self.processed_path, \"train_dataloader.pkl\")\n",
    "                )\n",
    "                dump(\n",
    "                    value=test_dataloader,\n",
    "                    filename=os.path.join(self.processed_path, \"test_dataloader.pkl\")\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                raise Exception(\"Cannot create the dataloader for further process\".capitalize())\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_images():\n",
    "        config_files = config()\n",
    "        files_path = config_files[\"path\"][\"files_path\"]\n",
    "        processed_path = config_files[\"path\"][\"processed_path\"]\n",
    "\n",
    "        if os.path.exists(files_path):\n",
    "            test_dataloader = load(\n",
    "                filename=os.path.join(processed_path, \"test_dataloader.pkl\")\n",
    "            )\n",
    "\n",
    "            X, y = next(iter(test_dataloader))\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Cannot load the dataloader for further process\".capitalize())\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        for index, image in enumerate(X):\n",
    "            image_X = image.squeeze().permute(1, 2, 0).cpu().detach().numpy()\n",
    "            image_y = y[index].squeeze().permute(1, 2, 0).cpu().detach().numpy()\n",
    "\n",
    "            image_X = (image_X - image_X.min())/(image_X.max() - image_X.min())\n",
    "            image_y = (image_y - image_y.min())/(image_y.max() - image_y.min())\n",
    "\n",
    "            plt.subplot(2* 2, 2 * 4, 2 * index + 1)\n",
    "            plt.imshow(image_X)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"X\")\n",
    "\n",
    "            plt.subplot(2* 2, 2 * 4, 2 * index + 2)\n",
    "            plt.imshow(image_y)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"y\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(files_path, \"images.png\")) if os.path.exists(files_path) else \"Cannot be saved the images\".capitalize()\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def dataset_details():\n",
    "        config_files = config()\n",
    "\n",
    "        files_path = config_files[\"path\"][\"files_path\"]\n",
    "\n",
    "        train_dataloader = load(os.path.join(\n",
    "            config_files[\"path\"][\"processed_path\"], \"train_dataloader.pkl\"\n",
    "        ))\n",
    "        test_dataloader = load(os.path.join(\n",
    "            config_files[\"path\"][\"processed_path\"], \"test_dataloader.pkl\"\n",
    "        ))\n",
    "\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"train_data(total)\": str(sum(X.size(0) for X, _ in train_dataloader)),\n",
    "                \"test_data(total)\": str(sum(X.size(0) for X, _ in test_dataloader)),\n",
    "                \"total_data\": str(sum(X.size(0) for X, _ in train_dataloader)\n",
    "                + sum(X.size(0) for X, _ in test_dataloader)),\n",
    "                \"train_data_shape\": str(train_dataloader.dataset[0][0].shape),\n",
    "                \"test_data_shape\": str(test_dataloader.dataset[0][0].shape)\n",
    "            },\n",
    "            index=[\"Quantity\"]\n",
    "        ).T.to_csv(os.path.join(files_path, \"dataset_details.csv\") if os.path.exists(files_path)\\\n",
    "            else \"Cannot be saved the dataset into csv format\".capitalize())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loader = Loader(\n",
    "        image_path=\"/Users/shahmuhammadraditrahman/Desktop/images.zip\",\n",
    "        unpaired_images=True,\n",
    "        split_size=0.50\n",
    "    )\n",
    "    #loader.unzip_folder()\n",
    "    loader.create_dataloader()\n",
    "    loader.plot_images()\n",
    "    loader.dataset_details()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
